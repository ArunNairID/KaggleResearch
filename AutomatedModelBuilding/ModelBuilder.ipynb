{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Model Builder</h1>\n",
    "\n",
    "<p>This program will train different models and combine their predictions to make an overall prediction.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ModelBuilder():\n",
    "    \n",
    "    def __init__(self, rf=True, xgb=True):\n",
    "        self.rf = rf\n",
    "        self.xgb = xgb\n",
    "        \n",
    "    def average_output(self):\n",
    "        rf_pred = pd.read_csv('./output/titanic_output_RandomForest.csv',\n",
    "                              index_col=0, header=0).values\n",
    "        xgb_pred = pd.read_csv('./output/titanic_output_XGBoost.csv',\n",
    "                               index_col=0, header=0).values\n",
    "        \n",
    "        \n",
    "        self.pred = (rf_pred + 1.2*xgb_pred) / 2.2\n",
    "        return self.pred\n",
    "    \n",
    "    def majority_output(self):\n",
    "        rf_pred = pd.read_csv('./output/titanic_output_RandomForest.csv',\n",
    "                              index_col=0, header=0).values.ravel()\n",
    "        xgb_pred = pd.read_csv('./output/titanic_output_XGBoost.csv',\n",
    "                               index_col=0, header=0).values.ravel()\n",
    "        \n",
    "        self.pred = [rf_pred[x] if rf_pred[x] == xgb_pred[x] else 0 for x in range(len(rf_pred))]\n",
    "        return self.pred\n",
    "    \n",
    "    def write_output(self, output_file='output.csv', header=['Id', 'Result'],\n",
    "                    out_dir='./output/'):\n",
    "        # create output dir if it does not exist\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "            \n",
    "        self.ids = pd.read_csv('./output/titanic_output_RandomForest.csv',\n",
    "                               header=0).values[:, 0].astype(int)\n",
    "        print(self.ids)\n",
    "        self.pred = np.ravel(self.pred)\n",
    "        print(self.pred)\n",
    "        \n",
    "        # write output to a file\n",
    "        prediction_file = open(out_dir+output_file, 'w')\n",
    "        open_file_object = csv.writer(prediction_file, lineterminator='\\n')\n",
    "        open_file_object.writerow(header)\n",
    "        data = zip(self.ids, self.pred)\n",
    "        open_file_object.writerows(data)\n",
    "        prediction_file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 892  893  894  895  896  897  898  899  900  901  902  903  904  905  906\n",
      "  907  908  909  910  911  912  913  914  915  916  917  918  919  920  921\n",
      "  922  923  924  925  926  927  928  929  930  931  932  933  934  935  936\n",
      "  937  938  939  940  941  942  943  944  945  946  947  948  949  950  951\n",
      "  952  953  954  955  956  957  958  959  960  961  962  963  964  965  966\n",
      "  967  968  969  970  971  972  973  974  975  976  977  978  979  980  981\n",
      "  982  983  984  985  986  987  988  989  990  991  992  993  994  995  996\n",
      "  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011\n",
      " 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026\n",
      " 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041\n",
      " 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056\n",
      " 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071\n",
      " 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086\n",
      " 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101\n",
      " 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116\n",
      " 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131\n",
      " 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146\n",
      " 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161\n",
      " 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176\n",
      " 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191\n",
      " 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206\n",
      " 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221\n",
      " 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236\n",
      " 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251\n",
      " 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266\n",
      " 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281\n",
      " 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296\n",
      " 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 1 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 1 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "builder = ModelBuilder()\n",
    "\n",
    "builder.majority_output()\n",
    "builder.write_output(output_file='titanic_output_avg.csv', header=['PassengerId', 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
