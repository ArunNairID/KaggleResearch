{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "    \"\"\"A class to choose and train a random forest model\"\"\"\n",
    "    \"\"\"This implements the sklearn Random Forest Model\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir='./processed_data/', regressor=False, n_jobs=1):\n",
    "        \"\"\"Initializes the random forest class\"\"\"\n",
    "        \n",
    "        # Create an initialization function that will allow for\n",
    "        # a saved model to be loaded\n",
    "        \n",
    "        self.n_jobs = n_jobs\n",
    "        self.regressor = regressor\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "        if regressor:\n",
    "            self.model = RandomForestRegressor()\n",
    "        else:\n",
    "            self.model = RandomForestClassifier()\n",
    "            \n",
    "        self.params = {}\n",
    "        self.features = []\n",
    "        \n",
    "    def read_data(self):\n",
    "        \"\"\"Read in the data from the specified directory\"\"\"\n",
    "        \n",
    "        self.cv_X_df = pd.read_csv(self.data_dir+'cv_X.csv', header=0, index_col=0)\n",
    "        self.cv_X = self.cv_X_df.values\n",
    "        self.cv_y_df = pd.read_csv(self.data_dir+'cv_y.csv', header=0, index_col=0)\n",
    "        self.cv_y = self.cv_y_df.values\n",
    "        self.cv_ids_df = pd.read_csv(self.data_dir+'cv_ids.csv', header=0, index_col=0)\n",
    "        self.train_X_df = pd.read_csv(self.data_dir+'train_X.csv', header=0, index_col=0)\n",
    "        self.train_y_df = pd.read_csv(self.data_dir+'train_y.csv', header=0, index_col=0)\n",
    "        self.train_ids_df = pd.read_csv(self.data_dir+'train_ids.csv', header=0, index_col=0)\n",
    "        self.test_X_df = pd.read_csv(self.data_dir+'test_X.csv', header=0, index_col=0)\n",
    "        self.test_ids_df = pd.read_csv(self.data_dir+'test_ids.csv', header=0, index_col=0)\n",
    "        \n",
    "    def get_feature_importances(self):\n",
    "        \"\"\"Trains a basic random forest to get a list of feature importances\"\"\"\n",
    "        \n",
    "        importance_tree = RandomForestRegressor(n_jobs=1,\n",
    "                                random_state=1,\n",
    "                                n_estimators=100,\n",
    "                                max_features='sqrt',\n",
    "                                max_depth=10)\n",
    "        \n",
    "        # train a basic model so that we can access feature importances\n",
    "        cv_X = self.cv_X_df.values\n",
    "        cv_y = np.ravel(self.cv_y_df.values)\n",
    "        importance_tree.fit(cv_X, cv_y)\n",
    "        self.feature_importances = importance_tree.feature_importances_\n",
    "        \n",
    "        # sort the features by importances, most important first\n",
    "        self.sorted_features = self.feature_importances.argsort()[::-1]\n",
    "        \n",
    "        return self.sorted_features\n",
    "            \n",
    "    def select_features(self):\n",
    "        \"\"\"Select features from the dataset by using feature importances\n",
    "        to add features one by one for selection\"\"\"\n",
    "        \n",
    "        # TODO:\n",
    "        #   - THINK OF OTHER TYPES OF FEATURE SELECTION\n",
    "        #     BACKWARD FEATURE SELECTION?\n",
    "        \n",
    "        # which features to add, in order\n",
    "        self.sorted_features = self.get_feature_importances()\n",
    "        \n",
    "        cv_X = self.cv_X_df.values\n",
    "        cv_X_selected = cv_X[:, self.sorted_features[:1]]\n",
    "        for feature in self.sorted_features:\n",
    "            \n",
    "            # format data so that it can be added easily\n",
    "            added_feat = np.transpose(cv_X[:, feature])\n",
    "            added_feat.shape += (1, )\n",
    "            \n",
    "            # append data to the next column\n",
    "            cv_X_selected = np.append(cv_X_selected, added_feat, axis=1)\n",
    "            \n",
    "            # train a model with the augmented data\n",
    "            \n",
    "            \n",
    "            # have an evaluation metric to measure performance of added features\n",
    "            \n",
    "        \n",
    "        \n",
    "        self.selected_features = self.features\n",
    "        \n",
    "        return self.selected_features\n",
    "        \n",
    "    def tune_params(self):\n",
    "        \"\"\"Function to handle tuning hyperparameters of the model\"\"\"\n",
    "        \n",
    "        # TODO:\n",
    "        #   - PERFORM HYPERPARAMETER SEARCH HERE\n",
    "        self.params = self.params\n",
    "        \n",
    "    def train_model(self):\n",
    "        \"\"\"Trains the model on all training data\n",
    "        and returns a model to be used for prediction\"\"\"\n",
    "        train_X = self.train_X_df.values\n",
    "        train_y = np.ravel(self.train_y_df.values)\n",
    "        self.model.fit(train_X, train_y)\n",
    "        \n",
    "    def predict_output(self):\n",
    "        \"\"\"Make predictions on test data.\"\"\"\n",
    "        pred = self.model.predict(self.test_X_df.values)\n",
    "        return pred\n",
    "        \n",
    "    def get_model(self):\n",
    "        \"\"\"Return the model used for prediction\"\"\"\n",
    "        \n",
    "        # TODO:\n",
    "        #    - WHAT IS BEST FORMAT TO RETURN THIS?? \n",
    "        #      JUST RETURN THE SKLEAN MODEL OR RETURN COPY OF ITSELF?\n",
    "        \n",
    "        return self.model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2]\n",
      "[1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForest()\n",
    "\n",
    "model.read_data()\n",
    "\n",
    "imp = model.get_feature_importances()\n",
    "print(imp)\n",
    "\n",
    "model.select_features()\n",
    "\n",
    "model.tune_params()\n",
    "\n",
    "model.train_model()\n",
    "\n",
    "pred = model.predict_output()\n",
    "print(pred)\n",
    "\n",
    "train_model = model.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
