{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "\n",
    "# define some constants\n",
    "n_jobs = 3\n",
    "num_features_cat = 20\n",
    "num_features_cont = 10\n",
    "train_size = 188318\n",
    "test_size = 125546\n",
    "data_dir = '../data/'\n",
    "xgboost_data_dir = '../xgboost_data/'\n",
    "\n",
    "# read in the train dataset\n",
    "print('loading data...')\n",
    "df_cont = pd.read_csv(data_dir+'continuous_all.csv', header=0, index_col=0)\n",
    "df_cat = pd.read_csv(data_dir+'categorical_all.csv', header=0, index_col=0)\n",
    "df_y = pd.read_csv(data_dir+'y_all.csv', header=0, index_col=0)\n",
    "\n",
    "df_test_cont = pd.read_csv(data_dir+'continuous_test_all.csv', header=0, index_col=0)\n",
    "df_test_cat = pd.read_csv(data_dir+'categorical_test_all.csv', header=0, index_col=0)\n",
    "\n",
    "X_cont = df_cont.values\n",
    "X_cat = df_cat.values\n",
    "y = np.ravel(df_y.values)\n",
    "\n",
    "# create a Random Forest Classifier\n",
    "print('creating a model...')\n",
    "# create a tree to select features\n",
    "tree_cat = RandomForestRegressor(n_jobs=n_jobs,\n",
    "    random_state=1, n_estimators=10,\n",
    "    max_features='sqrt', max_depth=10)\n",
    "tree_cont = RandomForestRegressor(n_jobs=n_jobs,\n",
    "    random_state=1, n_estimators=10,\n",
    "    max_features='sqrt', max_depth=10)\n",
    "\n",
    "# some feature selection\n",
    "print('selecting features...')\n",
    "\n",
    "# use variance threshold to select features\n",
    "# many of the features are in categories with few vars\n",
    "selector_variance_cat = VarianceThreshold(threshold=0.1)\n",
    "X_cat = selector_variance_cat.fit_transform(X_cat)\n",
    "print('shape of X_cat after variance threshold')\n",
    "print(X_cat.shape)\n",
    "\n",
    "# create a basic tree for continuous features\n",
    "print('fitting tree to continuous data...')\n",
    "tree_cont.fit(X_cont, y)\n",
    "feature_importances_cont = tree_cont.feature_importances_\n",
    "feature_mapping_cont = {importance:idx for idx, importance in \\\n",
    "    enumerate(feature_importances_cont)}\n",
    "sorted_features_cont = feature_importances_cont.argsort()\n",
    "sorted_indices_cont = []\n",
    "print(sorted_features_cont)\n",
    "for x in sorted_features_cont[:num_features_cont]:\n",
    "    sorted_indices_cont.insert(0, x)\n",
    "\n",
    "# create a basic tree for categorical features\n",
    "print('fitting tree to categorical data...')\n",
    "tree_cat.fit(X_cat, y)\n",
    "feature_importances_cat = tree_cat.feature_importances_\n",
    "feature_mapping_cat = {importance:idx for idx, importance in \\\n",
    "    enumerate(feature_importances_cat)}\n",
    "sorted_features_cat = feature_importances_cat.argsort()\n",
    "sorted_indices_cat = []\n",
    "print(sorted_features_cat)\n",
    "for x in sorted_features_cat[:num_features_cat]:\n",
    "    sorted_indices_cat.insert(0, x)\n",
    "\n",
    "    \n",
    "print('writing output data...')\n",
    "df_cont_new = df_cont.iloc[:, sorted_indices_cont[:num_features_cont]]\n",
    "df_cont_new.to_csv(path_or_buf=xgboost_data_dir+'continuous_selected.csv')\n",
    "\n",
    "df_cat_new = df_cat.iloc[:, sorted_indices_cat[:num_features_cat]]\n",
    "df_cat_new.to_csv(path_or_buf=xgboost_data_dir+'categorical_selected.csv')\n",
    "\n",
    "df_test_cont_new = df_test_cont.iloc[:, sorted_indices_cont[:num_features_cont]]\n",
    "df_test_cont_new.to_csv(path_or_buf=xgboost_data_dir+'continuous_test_selected.csv')\n",
    "df_test_cat_new = df_test_cat.iloc[:, sorted_indices_cat[:num_features_cat]]\n",
    "df_test_cat_new.to_csv(path_or_buf=xgboost_data_dir+'categorical_test_selected.csv')\n",
    "\n",
    "X_cont_new = df_cont_new.values\n",
    "dump_svmlight_file(X_cont_new, y, xgboost_data_dir+'continuous_selected.dat',\n",
    "    zero_based=True, multilabel=False)\n",
    "\n",
    "X_test_cont_new = df_test_cont_new.values\n",
    "y_test = [ 0 for x in range(X_test_cont_new.shape[0])]\n",
    "dump_svmlight_file(X_test_cont_new, y_test, xgboost_data_dir+'continuous_test_selected.dat',\n",
    "    zero_based=True, multilabel=False)\n",
    "\n",
    "X_cat_new = df_cat_new.values\n",
    "print('df cat new head')\n",
    "print(df_cat_new.head())\n",
    "print('df cat new sum')\n",
    "print(df_cat_new.sum(axis=0))\n",
    "print('df y head')\n",
    "print(df_y.head())\n",
    "dump_svmlight_file(X_cat_new, y, xgboost_data_dir+'categorical_selected.dat',\n",
    "    zero_based=True, multilabel=False)\n",
    "\n",
    "X_test_cat_new = df_test_cat_new.values\n",
    "print('df cat new head')\n",
    "print(df_cat_new.head())\n",
    "dump_svmlight_file(X_test_cat_new, y_test, xgboost_data_dir+'categorical_test_selected.dat',\n",
    "    zero_based=True, multilabel=False)\n",
    "\n",
    "print('successfully wrote selected features to file!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
