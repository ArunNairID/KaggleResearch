{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "processing training data...\n",
      "X cat size\n",
      "(188318, 297)\n",
      "X cont size\n",
      "(188318, 14)\n",
      "(188318,)\n",
      "processing test data...\n",
      "X cat size\n",
      "(313864, 301)\n",
      "X cont size\n",
      "(313864, 14)\n",
      "(313864,)\n",
      "(125546,)\n",
      "[     4      6      9 ..., 587627 587629 587634]\n",
      "writing the data to .csv files...\n",
      "data has been processed and written to .csv files in ../data/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def build_features(df):\n",
    "    ''' build the features to use for the model'''\n",
    "    \n",
    "    # remove the labels and the ids for use\n",
    "    \n",
    "    y = df.pop('loss').values if 'loss' in list(df) else None\n",
    "    ids = df.pop('id').values\n",
    "\n",
    "    # create an imputer for imputer values later\n",
    "    imputer = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "    \n",
    "    # determine whether data is categorical or continuous\n",
    "    leave_one_out_cols = []\n",
    "    leave_one_out_counts = []\n",
    "    one_hot_cols = []\n",
    "    col_count = 0\n",
    "    for column in df:\n",
    "\n",
    "        # determine if the column is categorical or not\n",
    "        if 'cat' in column:\n",
    "\n",
    "            # create an encoding for categorical vars\n",
    "            mapping = {label:idx for idx, label in \\\n",
    "                enumerate(np.unique(df[column]))}\n",
    "\n",
    "            # convert everything into integers for categorical\n",
    "            df[column] = df[column].map(mapping)\n",
    "            df[column] = df[column].astype(int)\n",
    "            \n",
    "            unique_elems = len(mapping)\n",
    "\n",
    "            # perform leave-one-out counting\n",
    "            if unique_elems > 10:\n",
    "                #df[column] = [df[column].values.tolist().count(x)-1 for \\\n",
    "                #\tx in df[column].values.tolist()]\n",
    "                leave_one_out_cols.append(col_count)\n",
    "                # initialize counts to -1 for Leave One Out counting\n",
    "                leave_one_out_counts.append([-1 for x in range(unique_elems)])\n",
    "            else:\n",
    "                one_hot_cols.append(col_count)\n",
    "\n",
    "        col_count += 1\n",
    "\n",
    "    imputer = imputer.fit(df)\n",
    "    X = imputer.transform(df.values)\n",
    "    X_cat = X[:, :116]\n",
    "    X_cont = X[:, 116:]\n",
    "    \n",
    "    # transform data to leave-one-out counting\n",
    "    for num, col in enumerate(leave_one_out_cols):\n",
    "        # count the data\n",
    "        for idx, value in enumerate(X_cat[:, col]):\n",
    "            leave_one_out_counts[num][int(value)] = leave_one_out_counts[num][int(value)] + 1\n",
    "        # apply the counted data to form LOO data\n",
    "        for idx, value in enumerate(X_cat[:, col]):\n",
    "            X_cat[idx][col] = leave_one_out_counts[num][int(value)] \n",
    "            \n",
    "    # transform data to one-hot encoded\n",
    "    one_hot_encoder = OneHotEncoder(categorical_features=one_hot_cols, sparse=False)\n",
    "    X_cat = one_hot_encoder.fit_transform(X_cat)\n",
    "    \n",
    "    print('X cat size')\n",
    "    print(X_cat.shape)\n",
    "    print('X cont size')\n",
    "    print(X_cont.shape)\n",
    "    \n",
    "    return X_cat, X_cont, y, ids\n",
    "\n",
    "\n",
    "# define some constants\n",
    "n_jobs = 3\n",
    "data_dir = '../data/'\n",
    "train_size = 188318\n",
    "test_size = 125546\n",
    "\n",
    "# read in the train dataset\n",
    "print('loading data...')\n",
    "df_train = pd.read_csv(data_dir + 'train.csv', header=0)\n",
    "df_test = pd.read_csv(data_dir + 'test.csv', header=0)\n",
    "df_test = df_train.append(df_test)\n",
    "\n",
    "print('processing training data...')\n",
    "# process the training data alone for cross validation\n",
    "X_cat, X_cont, y, ids = build_features(df_train)\n",
    "\n",
    "print('processing test data...')\n",
    "# process the training and test data together\n",
    "X_test_cat, X_test_cont, y_test, ids_all = build_features(df_test)\n",
    "X_test_train = \n",
    "ids_test = ids_test[train_size:]\n",
    "\n",
    "print('converting data to dataframes...')\n",
    "df_cont = pd.DataFrame(X_cont)\n",
    "df_cat = pd.DataFrame(X_cat)\n",
    "df_y = pd.DataFrame(y)\n",
    "df_ids = pd.DataFrame(ids)\n",
    "\n",
    "df_test_cont = pd.DataFrame(X_test_cont)\n",
    "df_test_cat = pd.DataFrame(X_test_cat)\n",
    "df_test_y = pd.DataFrame(y_test)\n",
    "df_test_ids = pd.DataFrame(ids_test)\n",
    "\n",
    "print('writing the data to .csv files...')\n",
    "df_cont.to_csv(path_or_buf=data_dir+'continuous_all.csv')\n",
    "df_cat.to_csv(path_or_buf=data_dir+'categorical_all.csv')\n",
    "df_y.to_csv(path_or_buf=data_dir+'y_all.csv')\n",
    "df_ids.to_csv(path_or_buf=data_dir+'ids_all.csv')\n",
    "\n",
    "df_test_cont.to_csv(path_or_buf=data_dir+'continuous_test_all.csv')\n",
    "df_test_cat.to_csv(path_or_buf=data_dir+'categorical_test_all.csv')\n",
    "df_test_ids.to_csv(path_or_buf=data_dir+'ids_test_all.csv')\n",
    "\n",
    "print('data has been processed and written to .csv files in ' + data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
