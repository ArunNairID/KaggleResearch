{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training data...\n",
      "    test-mae-mean  test-mae-std  train-mae-mean  train-mae-std\n",
      "0     3036.694434     24.421653     3036.694434       2.713561\n",
      "1     3036.559253     24.421653     3036.559228       2.713542\n",
      "2     3036.394214     24.421653     3036.394189       2.713542\n",
      "3     3036.192505     24.421681     3036.192529       2.713542\n",
      "4     3035.946387     24.421653     3035.946313       2.713488\n",
      "5     3035.645679     24.421653     3035.645654       2.713495\n",
      "6     3035.278442     24.421681     3035.278467       2.713542\n",
      "7     3034.830078     24.421698     3034.830078       2.713502\n",
      "8     3034.282666     24.421630     3034.282617       2.713542\n",
      "9     3033.614258     24.421698     3033.614258       2.713481\n",
      "10    3032.798315     24.421670     3032.798267       2.713549\n",
      "11    3031.802222     24.421704     3031.802197       2.713535\n",
      "12    3030.586450     24.421687     3030.586426       2.713515\n",
      "13    3029.102856     24.421707     3029.102856       2.713587\n",
      "14    3027.292749     24.421696     3027.292749       2.713606\n",
      "15    3025.084790     24.421757     3025.084766       2.713553\n",
      "16    3022.392212     24.421868     3022.392261       2.713514\n",
      "17    3019.109863     24.422060     3019.109863       2.713537\n",
      "18    3015.110474     24.422158     3015.110425       2.713595\n",
      "19    3010.239795     24.422467     3010.239770       2.713532\n",
      "20    3004.311719     24.422794     3004.311719       2.713542\n",
      "21    2997.102441     24.423179     2997.102466       2.713428\n",
      "22    2988.343115     24.423633     2988.343140       2.713337\n",
      "23    2977.712646     24.424058     2977.712647       2.713114\n",
      "24    2964.830249     24.424000     2964.830273       2.712806\n",
      "25    2949.246143     24.424097     2949.246118       2.712260\n",
      "26    2930.431860     24.424896     2930.431885       2.711427\n",
      "27    2907.775488     24.426764     2907.775440       2.710369\n",
      "28    2880.575147     24.428971     2880.575146       2.708656\n",
      "29    2848.039966     24.434374     2848.039941       2.706440\n",
      "..            ...           ...             ...            ...\n",
      "70    1755.620373     19.581478     1749.908520       2.735349\n",
      "71    1756.058093     19.606840     1750.203833       2.737506\n",
      "72    1756.394580     19.591590     1750.419006       2.741911\n",
      "73    1756.665918     19.614810     1750.577185       2.732751\n",
      "74    1756.921338     19.583267     1750.688965       2.715398\n",
      "75    1757.099426     19.569754     1750.760962       2.710476\n",
      "76    1757.268640     19.560883     1750.833338       2.708847\n",
      "77    1757.393323     19.562078     1750.863513       2.716761\n",
      "78    1757.519873     19.538762     1750.880859       2.708295\n",
      "79    1757.601477     19.556903     1750.867737       2.710090\n",
      "80    1757.696887     19.538646     1750.853003       2.707593\n",
      "81    1757.782080     19.526641     1750.845886       2.708680\n",
      "82    1757.874500     19.479820     1750.823987       2.704991\n",
      "83    1757.913794     19.475909     1750.804065       2.712963\n",
      "84    1757.949036     19.488581     1750.774280       2.715289\n",
      "85    1758.033679     19.468899     1750.735437       2.712221\n",
      "86    1758.080298     19.485993     1750.684912       2.715099\n",
      "87    1758.079236     19.464417     1750.630603       2.727689\n",
      "88    1758.062585     19.465936     1750.569812       2.751095\n",
      "89    1758.082056     19.466969     1750.513355       2.738758\n",
      "90    1758.109131     19.478775     1750.457776       2.754459\n",
      "91    1758.151599     19.469777     1750.406629       2.737780\n",
      "92    1758.183057     19.457166     1750.368298       2.754580\n",
      "93    1758.225256     19.452685     1750.310852       2.731619\n",
      "94    1758.253162     19.434680     1750.252258       2.711798\n",
      "95    1758.279981     19.414518     1750.197986       2.702833\n",
      "96    1758.305627     19.365712     1750.131250       2.722397\n",
      "97    1758.341345     19.382635     1750.069409       2.713098\n",
      "98    1758.375330     19.365622     1750.013953       2.710855\n",
      "99    1758.394092     19.369916     1749.948401       2.716283\n",
      "\n",
      "[100 rows x 4 columns]\n",
      "[ 12438.43945312  15906.30566406   6978.52978516 ...,  15906.30566406\n",
      "  15906.30566406  15906.30566406]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sys\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "\n",
    "def write_hyperparams(hyperparams, fileName):\n",
    "    f = open(fileName, 'w')\n",
    "    f.write(' '.join(str(x) for x in hyperparams) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "def read_hyperparams(fileName):\n",
    "    f = open(fileName, 'r')\n",
    "    n_folds, n_estimators, max_depth, max_features, \\\n",
    "        score = f.read().split()\n",
    "    return int(n_folds), int(n_estimators), int(max_depth), \\\n",
    "        max_features, float(score)\n",
    "\n",
    "# define some constants\n",
    "xgboost_data_dir = '../xgboost_data/'\n",
    "data_dir = '../data/'\n",
    "hyperParamFile = 'hyperparams_cat.txt'\n",
    "n_folds = 3\n",
    "verbose_tree = 3\n",
    "verbose_grid = 0\n",
    "n_jobs = 3\n",
    "random_state = 1\n",
    "criterion = 'mae'\n",
    "\n",
    "# For xgboost\n",
    "param = {}\n",
    "param['objective'] = 'reg:gamma'\n",
    "param['nthread'] = 2\n",
    "param['eval_metric'] = 'mae'\n",
    "# maximum depth of tree\n",
    "param['max_depth'] = 6  #3-10\n",
    "# analogous to learning rate\n",
    "param['eta'] = 0.05  #0.01-0.02\n",
    "# larger values prevent overfitting\n",
    "param['min_child_weight'] = 0.7  #0-1\n",
    "param['silent'] = 1  # prints messages to screen (1 silences these)\n",
    "param['tree_method'] = 'auto'\n",
    "param['lambda'] = 0  #0-1\n",
    "param['alpha'] = 0  #0-1\n",
    "num_boost_rounds = 500\n",
    "\n",
    "# read in the train dataset\n",
    "print('loading training data...')\n",
    "# for xgboost\n",
    "dtrain = xgb.DMatrix(xgboost_data_dir+'categorical_selected.dat')\n",
    "\n",
    "evaluations = xgb.cv(params=param, dtrain=dtrain, num_boost_round=num_boost_rounds,\n",
    "            nfold=10)\n",
    "print(evaluations)\n",
    "\n",
    "\n",
    "tree = xgb.train( param, dtrain, num_boost_rounds, evallist)\n",
    "tree.save_model('prac.model')\n",
    "\n",
    "dtest = xgb.DMatrix(xgboost_data_dir+'categorical_test_selected.dat')\n",
    "y_pred = tree.predict(dtest)\n",
    "\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for sklearn\n",
    "df_cat = pd.read_csv(xgboost_data_dir+'categorical_selected.csv', header=0, index_col=0)\n",
    "df_y = pd.read_csv(data_dir+'y_all.csv', header=0, index_col=0)\n",
    "\n",
    "X = df_cat.values\n",
    "y = np.ravel(df_y.values)\n",
    "\n",
    "# create a Random Forest Classifier\n",
    "print('creating a model...')\n",
    "n_estimators_def = 100\n",
    "max_features_def = 'sqrt'\n",
    "max_depth_def = 10\n",
    "#n_estimators_range = [10, 50]\n",
    "#max_features_range = ['sqrt']\n",
    "#max_depth_range = [10, 30]\n",
    "#param_grid = {'n_estimators': n_estimators_range, 'max_features': max_features_range,\n",
    "#    'max_depth': max_depth_range}\n",
    "\n",
    "# create a tree to train the models on\n",
    "tree = RandomForestRegressor(criterion=criterion, verbose=verbose_tree, n_jobs=n_jobs,\n",
    "    random_state=random_state, n_estimators=n_estimators_def,\n",
    "    max_features=max_features_def, max_depth=max_depth_def)\n",
    "\n",
    "# some feature selection\n",
    "#print('selecting features...')\n",
    "#print('input feature shape: ')\n",
    "#print(X.shape)\n",
    "#tree.fit(X, y)\n",
    "#feature_select = SelectFromModel(tree, prefit=True, threshold=feature_threshold)\n",
    "##print(tree.feature_importances_.sort())\n",
    "#X_new = feature_select.transform(X)\n",
    "#print('new input feature shape: ')\n",
    "#print(X_new.shape)\n",
    "\n",
    "# perform a grid search to tune the paramteres\n",
    "#print('grid search to tune hyperparameters...')\n",
    "#gs = GridSearchCV(estimator=tree,\n",
    "#\tparam_grid=param_grid, scoring=None,\n",
    "#\tcv=n_folds, n_jobs=n_jobs, verbose=verbose_grid)\n",
    "#gs = gs.fit(X_new, y)\n",
    "#print(gs.scorer_)\n",
    "#print('best score from grid search: %.3f' % gs.best_score_)\n",
    "#print(gs.best_params_)\n",
    "#best = gs.best_params_\n",
    "#n_estimators_gs = best['n_estimators']\n",
    "#max_depth_gs = best['max_depth']\n",
    "#max_features_gs = best['max_features']\n",
    "\n",
    "# run some cross validation\n",
    "print('running cross validation to determine accuracy of model...')\n",
    "scores = []\n",
    "splits = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "for train, test in splits.split(X):\n",
    "    tree.fit(X[train], y[train])\n",
    "    predicted = tree.predict(X[test])\n",
    "    score = mean_absolute_error(y[test], predicted)\n",
    "    scores.append(score)\n",
    "print(scores)\n",
    "\n",
    "# determine which features to write to the file\n",
    "n_estimators = n_estimators_def\n",
    "max_depth = max_depth_def\n",
    "max_features=max_features_def\n",
    "score = np.mean(scores)\n",
    "\n",
    "print('writing the data to file...')\n",
    "params = (n_folds, n_estimators, max_depth, max_features, score)\n",
    "write_hyperparams(params, hyperParamFile)\n",
    "n_folds, n_estimators, max_depth, max_features, \\\n",
    "    score = read_hyperparams(hyperParamFile)\n",
    "print(n_folds, n_estimators, max_depth, max_features, score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
